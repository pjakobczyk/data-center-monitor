
name: Scrape HTML Sources

on:
  schedule:
    - cron: '0 7 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install selenium beautifulsoup4

    - name: Install Chrome & ChromeDriver (fixed version)
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip curl
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -f install -y

        DRIVER_VERSION=138.0.7204.93
        wget https://chromedriver.storage.googleapis.com/$DRIVER_VERSION/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver

    - name: Run scraper
      run: python html_selenium_scraper.py

    - name: Commit results
      run: |
        git config --global user.email "github-actions@example.com"
        git config --global user.name "GitHub Actions"
        git add scraped_results.json
        git commit -m "Update scraped results" || echo "No changes to commit"
        git push

    - name: Send webhook notification
      run: |
        curl -X POST -H "Content-Type: application/json"         -d "{\"content\": \"ðŸ“¡ New scraped data uploaded: scraped_results.json\"}"         ${{ secrets.WEBHOOK_URL }}

    - name: Send email with result file
      uses: dawidd6/action-send-mail@v3
      with:
        server_address: smtp.gmail.com
        server_port: 465
        username: ${{ secrets.EMAIL_USERNAME }}
        password: ${{ secrets.EMAIL_PASSWORD }}
        subject: "Daily Data Center Scraper Results"
        to: your@email.com
        from: "DataCenter Bot <bot@email.com>"
        body: "Attached is today's data center news results."
        attachments: scraped_results.json
